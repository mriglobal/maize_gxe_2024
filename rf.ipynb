{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6cd8ba-466d-4859-a255-57b35fc85a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "training_path = '/home/colinprice/Documents/Maize_GxE_Competition/Maize_GxE_Competition_Data_2024_UPDATE/Training_data/'\n",
    "\n",
    "trait_data = pd.read_csv(training_path+\"1_Training_Trait_Data_2014_2023.csv\")\n",
    "\n",
    "meta_data = pd.read_csv(training_path+\"2_Training_Meta_Data_2014_2023.csv\")\n",
    "\n",
    "soil_data = pd.read_csv(training_path+\"3_Training_Soil_Data_2015_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12c1fa2-7a7b-4aa6-89d2-238e11a9ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all dataframes: ['Env']\n",
      "         Env  Year_x Field_Location  ...     LL__8     LL__9    LL__10\n",
      "0  IAH1_2015    2015           IAH1  ...  0.090938  0.090938  0.090938\n",
      "1  IAH1_2015    2015           IAH1  ...  0.090938  0.090938  0.090938\n",
      "2  IAH1_2015    2015           IAH1  ...  0.090938  0.090938  0.090938\n",
      "3  IAH1_2015    2015           IAH1  ...  0.090938  0.090938  0.090938\n",
      "4  IAH1_2015    2015           IAH1  ...  0.090938  0.090938  0.090938\n",
      "\n",
      "[5 rows x 717 columns]\n",
      "         Env  Year  ... Days_Weather_Station Days_to_Report\n",
      "0  IAH1_2015  2015  ...                  NaN            NaN\n",
      "1  IAH1_2015  2015  ...                  NaN            NaN\n",
      "2  IAH1_2015  2015  ...                  NaN            NaN\n",
      "3  IAH1_2015  2015  ...                  NaN            NaN\n",
      "4  IAH1_2015  2015  ...                  NaN            NaN\n",
      "\n",
      "[5 rows x 714 columns]\n",
      "Number of rows in the combined dataframe: 114915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362512/1658712467.py:64: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_data[date_col] = pd.to_datetime(combined_data[date_col], errors='coerce')\n",
      "/tmp/ipykernel_362512/1658712467.py:64: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  combined_data[date_col] = pd.to_datetime(combined_data[date_col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "EC_data = pd.read_csv(training_path+\"6_Training_EC_Data_2014_2023.csv\")\n",
    "\n",
    "def find_common_columns(*dataframes):\n",
    "    \"\"\"\n",
    "    This function takes multiple pandas DataFrame objects as input and returns a list\n",
    "    of columns that are common to all dataframes.\n",
    "    \"\"\"\n",
    "    # Convert the column names of the first dataframe to a set\n",
    "    common_columns = set(dataframes[0].columns)\n",
    "    \n",
    "    # Find the intersection with the column names of the other dataframes\n",
    "    for df in dataframes[1:]:\n",
    "        common_columns.intersection_update(df.columns)\n",
    "    \n",
    "    return list(common_columns)\n",
    "\n",
    "# Example usage with your loaded dataframes\n",
    "common_columns = find_common_columns(trait_data, meta_data, soil_data, EC_data)\n",
    "\n",
    "print(\"Common columns across all dataframes:\", common_columns)\n",
    "# Just ENV\n",
    "# Merge Trait Data and \n",
    "\n",
    "\n",
    "combined_data = pd.merge(trait_data, meta_data, on='Env', how='inner')\n",
    "combined_data = pd.merge(combined_data, soil_data, on='Env', how='inner')\n",
    "combined_data = pd.merge(combined_data, EC_data, on='Env', how='inner')\n",
    "\n",
    "# Picking Lower Left as the coordinate to base things on arbitrarily\n",
    "columns_to_drop = [\n",
    "    'Year_y', 'City', 'Experiment_Code', 'Farm', 'Field', \n",
    "    'Trial_ID (Assigned by collaborator for internal reference)', \n",
    "    'Soil_Taxonomic_ID and horizon description, if known', \n",
    "    'Weather_Station_Serial_Number (Last four digits, e.g. m2700s#####)', \n",
    "    'Pre-plant_tillage_method(s)', 'In-season_tillage_method(s)', \n",
    "    'Type_of_planter (fluted cone; belt cone; air planter)', \n",
    "    'System_Determining_Moisture', 'Pounds_Needed_Grain_Moisture', \n",
    "    'Issue/comment_#1', 'Issue/comment_#2', 'Issue/comment_#3', \n",
    "    'Issue/comment_#4', 'Issue/comment_#5', 'Issue/comment_#6', \n",
    "    'Issue/comment_#7', 'Issue/comment_#8', 'Cardinal_Heading_Pass_1', \n",
    "    'LabID', 'Texture', 'Comments',\n",
    "    'Latitude_of_Field_Corner_#2 (lower right)',\n",
    "    'Longitude_of_Field_Corner_#2 (lower right)',\n",
    "    'Latitude_of_Field_Corner_#3 (upper right)',\n",
    "    'Longitude_of_Field_Corner_#3 (upper right)',\n",
    "    'Latitude_of_Field_Corner_#4 (upper left)',\n",
    "    'Longitude_of_Field_Corner_#4 (upper left)',\n",
    "    'Hybrid_orig_name',\n",
    "    'Range',\n",
    "    'Pass',\n",
    "    'Plot_Area_ha',\n",
    "    'Pounds_Needed_Soil_Moisture'\n",
    "]\n",
    "\n",
    "# Drop the columns from the dataframe, modifying it in place\n",
    "combined_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "print(combined_data.head())\n",
    "\n",
    "date_columns = ['Date_Planted', 'Date_Harvested', \n",
    "                'Date_weather_station_placed', 'Date_weather_station_removed',\n",
    "                'Date Received', 'Date Reported']\n",
    "\n",
    "for date_col in date_columns:\n",
    "    combined_data[date_col] = pd.to_datetime(combined_data[date_col], errors='coerce')\n",
    "\n",
    "# Calculate the differences in days between the relevant columns\n",
    "combined_data['Days_to_Harvest'] = (combined_data['Date_Harvested'] - combined_data['Date_Planted']).dt.days\n",
    "combined_data['Days_Weather_Station'] = (combined_data['Date_weather_station_removed'] - combined_data['Date_weather_station_placed']).dt.days\n",
    "combined_data['Days_to_Report'] = (combined_data['Date Reported'] - combined_data['Date Received']).dt.days\n",
    "\n",
    "combined_data.rename(columns={'Year_x': 'Year'}, inplace=True)\n",
    "\n",
    "# Drop the original date columns\n",
    "columns_to_drop = ['Date_Planted', 'Date_Harvested', \n",
    "                   'Date_weather_station_placed', 'Date_weather_station_removed',\n",
    "                   'Date Received', 'Date Reported']\n",
    "\n",
    "combined_data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame to verify changes\n",
    "print(combined_data.head())\n",
    "\n",
    "print(\"Number of rows in the combined dataframe:\", combined_data.shape[0])\n",
    "\n",
    "\n",
    "columns_to_onehot_encode = [\n",
    "    'Treatment', 'Previous_Crop', 'Irrigated']\n",
    "\n",
    "onehot_encoded_data = pd.get_dummies(combined_data[columns_to_onehot_encode], columns=columns_to_onehot_encode)\n",
    "combined_data.drop(columns=columns_to_onehot_encode, inplace=True)\n",
    "combined_data = pd.concat([combined_data, onehot_encoded_data], axis=1)\n",
    "\n",
    "# Drop to not learn over\n",
    "columns_to_not_learn_over = [\n",
    "    'Env', 'Year', 'Field_Location', 'Experiment', 'Replicate', 'Block', 'Plot', 'Hybrid', 'Hybrid_Parent1',\n",
    "    'Hybrid_Parent2']\n",
    "\n",
    "combined_data = combined_data.drop(columns=columns_to_not_learn_over, inplace=False)\n",
    "combined_data.fillna(0, inplace=True)\n",
    "\n",
    "y = combined_data['Yield_Mg_ha'] # Target variable\n",
    "combined_data.drop(columns='Yield_Mg_ha', inplace=True)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot_encoded_data_columns = set(onehot_encoded_data.columns)\n",
    "combined_data_columns = set(combined_data.columns)\n",
    "\n",
    "remaining_columns = combined_data_columns - onehot_encoded_data_columns\n",
    "remaining_columns_list = list(remaining_columns)\n",
    "\n",
    "combined_data[remaining_columns_list] = scaler.fit_transform(combined_data[remaining_columns_list])\n",
    "\n",
    "# drop the trait data we wont have for test set\n",
    "columns_to_drop_from_trait = ['Stand_Count_plants', 'Pollen_DAP_days', 'Silk_DAP_days', 'Plant_Height_cm', 'Ear_Height_cm', 'Root_Lodging_plants', 'Stalk_Lodging_plants', 'Grain_Moisture', 'Twt_kg_m3']\n",
    "combined_data.drop(columns=columns_to_drop_from_trait, inplace=True)\n",
    "X = combined_data  # Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3acd6790-80c9-448a-afa4-ce6b783232cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MSE: 7.763537899631382\n",
      "Overall Pearson Correlation Coefficient: 0.6630475691508398\n",
      "Split 1 - MSE: 7.698546694087034, Pearson r: 0.6632540812219363\n",
      "Split 2 - MSE: 7.905023986808943, Pearson r: 0.6585590535385055\n",
      "Split 3 - MSE: 7.561469337071198, Pearson r: 0.6690791903299977\n",
      "Split 4 - MSE: 7.734753570675763, Pearson r: 0.6640056404276505\n",
      "Split 5 - MSE: 7.917895909513966, Pearson r: 0.6603398802361093\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)  # You can adjust the number of trees\n",
    "\n",
    "# Setup 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "correlation_scores = []\n",
    "\n",
    "# Lists to store actual and predicted values for later analysis\n",
    "all_actuals = []\n",
    "all_predictions = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Store predictions and actuals\n",
    "    all_actuals.extend(y_test)\n",
    "    all_predictions.extend(y_pred)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(mse)\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    r, _ = pearsonr(y_test, y_pred)\n",
    "    correlation_scores.append(r)\n",
    "\n",
    "# Calculate and print overall performance\n",
    "overall_mse = np.mean(mse_scores)\n",
    "overall_r = np.mean(correlation_scores)\n",
    "print(f'Overall MSE: {overall_mse}')\n",
    "print(f'Overall Pearson Correlation Coefficient: {overall_r}')\n",
    "\n",
    "# Print per-split performance\n",
    "for i, (mse, r) in enumerate(zip(mse_scores, correlation_scores), 1):\n",
    "    print(f'Split {i} - MSE: {mse}, Pearson r: {r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908480d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "180 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "46 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "134 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/colinprice/miniconda3/envs/maize/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -7.7669988  -7.76729107 -7.76745054\n",
      " -7.76702859 -7.76731446 -7.76744395 -7.76699312 -7.76735021 -7.76748534\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -7.90449969 -7.90419435 -7.90437801\n",
      " -7.90358202 -7.90469075 -7.90503932 -7.90287449 -7.90344776 -7.90357564\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -7.76705634 -7.76734475 -7.76748454\n",
      " -7.767017   -7.76732991 -7.76746963 -7.76702792 -7.76736522 -7.76750346\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -7.7669988  -7.76729107 -7.76745054\n",
      " -7.76702859 -7.76731446 -7.76744395 -7.76699312 -7.76735021 -7.76748534]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best MSE: 7.72076520768308\n",
      "Pearson Correlation Coefficient: 0.6653537206838245\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=kf,\n",
    "                           scoring='neg_mean_squared_error',  # MSE scoring\n",
    "                           n_jobs=-1,\n",
    "                           verbose=2)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X)  # Assuming you want to predict the entire set or use a train/test split as needed\n",
    "\n",
    "# Calculate MSE and Pearson correlation\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r, _ = pearsonr(y, y_pred)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best MSE: {mse}\")\n",
    "print(f\"Pearson Correlation Coefficient: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664bf07-ab61-4f10-88d0-d0a500b625c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
